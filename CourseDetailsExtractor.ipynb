{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7eabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlwt\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "\n",
    "master_data = pd.read_json('course.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae8ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_num = len(master_data)\n",
    "# course_num = 1\n",
    "\n",
    "        \n",
    "for cr_num in range(course_num):\n",
    "    title = master_data.iloc[cr_num]['course']['title']\n",
    "    description = master_data.iloc[cr_num]['course']['description']\n",
    "    curr_len = len(master_data.iloc[cr_num]['meta']['curriculum'])\n",
    "    # startdate = master_data.iloc[cr_num]['course']['classTimings']['timings']\n",
    "    # india = master_data.iloc[cr_num]['course']['mobilePricing']['IN']\n",
    "    # USA = master_data.iloc[cr_num]['course']['mobilePricing']['US']\n",
    "    \n",
    "    \n",
    "\n",
    "    # for i in range(curr_len):\n",
    "    #     if 'parent' in list(master_data.iloc[cr_num]['meta']['curriculum'][i].keys()):\n",
    "    #         sheet1.write(14+i,1, master_data.iloc[cr_num]['meta']['curriculum'][i]['title'])\n",
    "    #     else:\n",
    "    #         sheet1.write(14+i,0, master_data.iloc[cr_num]['meta']['curriculum'][i]['title'])\n",
    "        \n",
    "    # file_name = 'data/'+str(cr_num)+\"_\"+title+'.xlsx'\n",
    "    # wb.save(file_name)\n",
    "    file_name = 'data/'+str(cr_num)+\"_\"+title+'.txt'\n",
    "    with open(file_name ,mode='a') as f:\n",
    "\n",
    "        f.writelines(f'Course Titel is {title}' + '\\n \\n')\n",
    "        f.writelines(f'Course desctiption is {description}' + '\\n \\n')\n",
    "        # f.writelines(f'Start date {startdate}' + '\\n \\n')\n",
    "        # f.writelines(f'Price in india {str(india)}' + '\\n \\n')\n",
    "        # f.writelines(f'Price in india {str(USA)}' + '\\n \\n')\n",
    "        f.writelines('Course Curriculum' + '\\n \\n')\n",
    "        \n",
    "\n",
    "    for i in range(curr_len):\n",
    "        Curriculum = master_data.iloc[cr_num]['meta']['curriculum'][i]['title']\n",
    "        with open(file_name , mode='a') as f:\n",
    "            f.writelines(f'     {Curriculum}' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c98854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a683a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('docs/course.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "789bd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "for i in range(len(data)):\n",
    "    length.append(set(['title', 'description', 'courseMeta', 'instructorsDetails', 'pricing', 'classTimings']).issubset(data['data'][i].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9e903e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': ['Building Scalable Applications',\n",
       "  'Understanding Scalability',\n",
       "  'Designing for Scalability',\n",
       "  'Microservices',\n",
       "  'Case Studies'],\n",
       " 'requirements': ['Dedication', 'Internet Connection'],\n",
       " 'features': ['Masterclass by Industry Veterans', 'Industry Expert Sessions'],\n",
       " 'language': 'english'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = data['data'][0]['courseMeta'][0]['overview']\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3effca81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    439\n",
       "True     170\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4a63cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_meta(name: str, data: dict, file: str):\n",
    "    if name in data.keys():\n",
    "        # print(data[name][0]['overview']['learn'])\n",
    "        for item in data[name][0]['overview']['learn']:\n",
    "            with open(file, mode='a') as f:\n",
    "                f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "faba15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_instructor(name: str, data: dict, file: str):\n",
    "    if name in data.keys():\n",
    "        for i in range(len(data[name])):\n",
    "            # print(data[name][i]['name'])\n",
    "            # print(data[name][i]['description'])\n",
    "            with open(file, mode='a') as f:\n",
    "                f.write(data[name][i]['name'] + '\\n')\n",
    "                # f.write(data[name][i]['description'] + '\\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "da6d5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_timings(name: str, data: dict, file: str):\n",
    "    if name in data.keys():\n",
    "        with open(file, mode='a') as f:\n",
    "            f.write(str(data[name]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "858bac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_price(name: str, data: dict, file: str):\n",
    "    if name in data.keys():\n",
    "        # print(data[name]['US'])\n",
    "        with open(file, mode='a') as f:\n",
    "            f.write(str(data[name]) + '\\n')\n",
    "            # f.write(str(data[name]['US']) + '\\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2f442ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_price('pricing', data['data'][0], 'file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a9b0b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'title',\n",
    "    'mode',\n",
    "    'description',\n",
    "    'classTimings',\n",
    "    'courseMeta',\n",
    "    'instructorsDetails',\n",
    "    'pricing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "19374783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6f65108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in columns:\n",
    "    for i in range(len(data)):        \n",
    "        if j == 'courseMeta':\n",
    "            get_data_meta(j, data['data'][i], 'test.txt')\n",
    "        elif j == 'instructorsDetails':\n",
    "            get_data_instructor(j, data['data'][i], 'test.txt')\n",
    "        elif j == 'classTimings':\n",
    "            get_data_timings(j, data['data'][i], 'test.txt')\n",
    "        elif j == 'pricing':\n",
    "            get_data_price(j, data['data'][i], 'test.txt')\n",
    "        else:\n",
    "            get_data_direct(j, data['data'][i], 'test.txt')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98966b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'title': 'Course Title',\n",
    "    'mode': 'Mode of course',\n",
    "    'description': 'Course Description',\n",
    "    'classTimings': 'Timings of class',\n",
    "    'courseMeta': 'Curriculum of course',\n",
    "    'instructorsDetails': 'Instructors Details',\n",
    "    'pricing': \"Pricing details\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b1ac463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_direct(name: str, data: dict, file: str):\n",
    "    if name in data.keys():\n",
    "        with open(file, mode='a') as f:\n",
    "            # f.writelines(name + '\\n')\n",
    "            f.writelines(str(data[name]) + '\\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8144003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, j in columns.items():\n",
    "\n",
    "    for k in range(len(data)):\n",
    "        \n",
    "        file_name = 'data/'+str(k)+'.txt'\n",
    "        with open(file_name, mode='a') as f:\n",
    "            f.writelines(j + '\\n')\n",
    "        get_data_direct(i, data['data'][k], file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4065d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTSimpleVectorIndex, LLMPredictor, ServiceContext\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f576e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llm_predictor.base:Unknown max input size for gpt-3.5-turbo, using defaults.\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 295059 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x7fda8af57ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_index(directory_path):\n",
    "    num_outputs = 512\n",
    "\n",
    "    llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", verbose=True))\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "    docs = SimpleDirectoryReader(directory_path).load_data()\n",
    "\n",
    "    index = GPTSimpleVectorIndex.from_documents(docs, service_context=service_context)\n",
    "\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index\n",
    "\n",
    "construct_index('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "036eaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(input_text):\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    response = index.query(input_text, response_mode=\"compact\")\n",
    "    return response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b7de44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 590 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Priya Bhatia\n"
     ]
    }
   ],
   "source": [
    "print(chatbot(\"instructor of DSA with python course\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9c9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/bharath/drive/Personal_Learning/chatgpt-train/venv/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/media/bharath/drive/Personal_Learning/chatgpt-train/venv/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/media/bharath/drive/Personal_Learning/chatgpt-train/venv/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://b9b2eebbbdc85f6c67.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b9b2eebbbdc85f6c67.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1157 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 459 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 597 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 4 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1157 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 639 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 6 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 1156 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 11 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 639 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 6 tokens\n"
     ]
    }
   ],
   "source": [
    "iface = gr.Interface(fn=chatbot,\n",
    "                     inputs=gr.inputs.Textbox(lines=7, label=\"Enter your text\"),\n",
    "                     outputs=\"text\",\n",
    "                     title=\"Custom-trained AI Chatbot\")\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
